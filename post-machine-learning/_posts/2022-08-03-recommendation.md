---
layout: post
title : "Recommendation System"
description: >
    Basic knowledge of recommendation system.
sitemap: false
---

유저의 선호도, 과거 행동 데이터를 바탕으로 개인에 맞는 관심사를 제공하는 머신러닝 기법
{:.lead}

0. Table of Contents
{:toc}  


## 추천 시스템의 유형

고객이 좋아할 만한 걸 어떤 방식으로 찾아내느냐, 그 알고리즘에 따라 두 가지로 나뉜다.

1. **콘텐츠 기반 필터링**

2. **협업 필터링**

정확한 표현인지는 잘 모르겠지만, 콘텐츠 기반 필터링과 협업 필터링의 차이는 마치 통계와 머신러닝의 관계 같다. 기본적으로 두 가지 알고리즘 모두 고객이 이전에 좋아했던 제품과 "비슷한" 제품을 추천해 주는 측면에서는 같다. 그러나 콘텐츠 기반 필터링은, 고객이 좋아했던 제품과 "비슷한" 제품이 무엇인지를 사람의 기준으로 직접 찾아낸다. 반면 협업 필터링은 그 안에 숨겨져 있는 새로운 요인을 알고리즘적으로 찾아서 알아낸다. 콘텐츠 기반 필터링에서 "비슷한" 두 제품 간의 공통점을 쉽게 말할 수 있는 반면, 협업 필터링(특히 잠재 요인 협업 필터링)은 두 제품 간 어떤 공통점이 있는지를 명확하게 설명 못하지 않나, 싶어서 말한 예시이다.

협업 필터링은 **최근접 이웃 협업 필터링**과 **잠재 요인 협업 필터링**의 두 가지 알고리즘으로 다시 나뉘는데, 최근에는 행렬 분해 기법을 이용한 잠재 요인 협업 필터링을 추천 시스템에 사용하는 게 더 효과가 좋아 트렌드라고 한다.

![Full-width image](https://github.com/menmenmeng/menmenmeng.github.io/blob/main/assets/img/myown/%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C%ED%95%84%ED%84%B0%EB%A7%81.png?raw=true){:.lead loading="lazy"}
ref : https://velog.io/@ijune97/RecommendationAlgorithm
{:.figure}

### 콘텐츠 기반 필터링

고객이 A아이템을 선호할 때, A아이템과 콘텐츠가 비슷한 B아이템을 추천한다. 콘텐츠가 비슷하다는 말은? 앞에서 말했듯이 영화로 치자면 장르가 비슷하거나 배우가 비슷하거나 감독이 같다는 게 되고, 온라인 마켓에서의 제품으로 치면 카테고리가 비슷한 제품이다.


### 협업 필터링

협업 필터링은 취향이 비슷한 친구들에게 영화를 추천받는 것처럼 새로운 아이템을 추천해주는 알고리즘이다. 사용자의 행동 양식(예를 들면 평점을 얼마나 주었는가, 또는 장바구니에 이 제품을 담았는가)을 바탕으로 알고리즘을 만드는 경우가 많다.
사용자의 행동 양식은 수치적으로 **사용자-아이템 평점 매트릭스**로 표현될 수 있다. 이러한 데이터를 기반으로, 사용자가 아직 평가하지 않은 아이템을 예측 평가하는 것이 협업 필터링의 목적이다. 사용자-아이템 평점 매트릭스란 뭘까?

|         |**Item1**|**Item2**|**Item3**|**Item4**|
|:-------:|:-------:|:-------:|:-------:|:-------:|
|**User1**|        1|        2|         |         |
|**User2**|        1|        1|         |        4|
|**User3**|         |        5|        2|        2|
|**User4**|        2|         |        4|        5|
{:.stretch-table}

위의 표는 User1 ~ User4의 Item1 ~ Item4에 대한 평가를 숫자로 나타낸 것이다. 위와 같은 형태의 행렬을 사용자-아이템 평점 매트릭스라고 한다. 활용할 수 있는 모든 아이템에 대해 사용자의 평가를 행렬로 나타낸 것이며, Row는 개별 이용자, Column은 개별 아이템을 의미한다. 원체 제품에 대한 평점 등록이라는 것은 정말 감명깊은(어떤 의미로든) 경험을 제공하지 않은 이상, 대부분의 사용자가 귀찮아하는 절차 중 하나이다. 그래서 사용자-아이템 평점 행렬은 대체로 Sparse하다(희소행렬이라고 말할 수 있는지는 모르겠다. 희소행렬은 행렬 요소들의 값이 대부분 0인 행렬을 의미하는 것으로 알고 있음.).
협업 필터링은 다시 두 가지 방식으로 나뉜다. 최근접 이웃 협업 필터링, 그리고 잠재 요인 협업 필터링 방식이다. 두 방식 모두 사용자-아이템 평점 매트릭스에 의지해 추천을 수행한다.


## 협업 필터링

협업 필터링의 두 가지 방식에 대해 더 알아보았다.
{:.lead}

### 최근접 이웃 협업 필터링

Memory 협업 필터링이라고도 하며 또 다시, 사용자 기반, 그리고 아이템 기반으로 나뉜다. 둘의 차이점은 뭘까.

1. **사용자 기반** : 당신과 비슷한 고객들이 이 상품도 구매했습니다!

특정 사용자와 유사한 다른 사용자를 TOP-N(N명의 유사 사용자를 추출한다는 뜻으로 보임)으로 선정하여 그들의 취향에 잘 맞는 아이템을 추천한다. 여기서 TOP-N을 선정할 때는 사용자 간 유사하다는 평가를 어떻게 수치적으로 표현할지를 고민해야 하는데, 그와 관련된 내용이 코사인 유사도이다.(더 아래에 자세히 정리)

수치적인 부분은 건너뛰고 개념적으로, 사용자 간 유사하다는 건 무슨 뜻일까? 사용자 기반의 알고리즘에서는, 유저 A가 평가한 아이템들의 평점과 유저 B가 평가한 아이템들의 평점이 비슷하다면, A, B를 유사하다고 표현한다. 위의 사용자-아이템 평점 행렬을 다시 가져와 보겠다.

|         |**Item1**|**Item2**|**Item3**|**Item4**|
|:-------:|:-------:|:-------:|:-------:|:-------:|
|**User1**|        1|        2|         |         |
|**User2**|        1|        1|         |        4|
|**User3**|         |        5|        2|        2|
|**User4**|        2|         |        4|        5|
{:.stretch-table}

위의 행렬을 보고 User1, User2와 Item1, Item2에 관한 두 가지 현상을 확인할 수 있다.

- User1과 User2는 Item1, Item2에 대한 평점이 각각 (1, 2), 그리고 (1, 1)로 두 아이템을 거의 비슷하게 평가했다. 

- User2가 Item4에 4라는 높은 평점을 주었다.

이 두 가지 현상을 바탕으로 우리는 "User1은 User2와 비슷하므로, User2가 좋아했던 Item4를 User1이 좋아할 가능성이 높다"는 가설을 세울 수 있다. 즉 User1에게 Item4를 추천해줄 수 있다. 이게 사용자 기반의 추천 알고리즘이다.


2. **아이템 기반** : 당신이 선택한 상품과 비슷한 상품이 여기 있습니다!

사용자가 선택한 특정 아이템과 유사한 다른 아이템을 찾아 추천해주는 방식이다. 여기서 중요한 것은, 아이템 간의 속성의 공통점은 이 알고리즘에서 전혀! 중요하지 않다는 거다. 아이템 간 속성의 공통점을 찾아 비슷한 아이템을 찾아 주는 건 **콘텐츠 기반 필터링**이다.

그럼 협업 필터링에서의 아이템 간 유사성이란 뭘까? 콘텐츠 기반 필터링에 빗대어 설명하면, 아이템 기반 협업 필터링에서는 아이템이 받은 "평점"이 곧 그 아이템의 속성이 된다. 아까 사용했던 사용자-아이템 평점 행렬을 다시 갖고 왔다.

|         |**Item1**|**Item2**|**Item3**|**Item4**|
|:-------:|:-------:|:-------:|:-------:|:-------:|
|**User1**|        1|        2|         |         |
|**User2**|        1|        1|         |        4|
|**User3**|         |        5|        2|        2|
|**User4**|        2|         |        4|        5|
{:.stretch-table}

위의 행렬을 보면 User3, User4와 Item3, Item4에 대한 연관성이 보인다. 바로, Item3과 Item4는 User3과 User4에게서 각각 비슷한 평점을 받았다는 거다.

조금 복잡하고 헷갈리는데 풀어서 설명하자면, User3은 Item3과 Item4를 "비슷하게" 평점 2점짜리 애매~한 상품으로 받아들이며, User4는 Item3과 Item4를 "비슷하게" 평점 4~5점짜리 좋은 상품으로 받아들이고 있다. 평가가 긍정적이든 부정적이든, Item3과 Item4는 User3, User4에게 비슷한 상품으로 느껴진다는 거다. 즉, Item3과 Item4는 "비슷하다"고 가정할 수 있다.

그럼 다음은 추천해주는 일만 남았다. 행렬에서 **User2**가 Item4에 긍정적인 평점(4점)을 부여한 것을 볼 수 있다. Item3과 Item4가 비슷하다는 가정 하에, 우리는 User2에게 Item3도 추천해줄 수 있을 것이다.

물론 고작 두 명의 평점 유사성만으로 Item3과 Item4를 비슷한 것으로 단정짓긴 어렵다. 그렇지만 실제 사례에선 User도 많고, Item도 많다! 100명의 User와 100개의 Item이 있을 때, 이 중 40명이 Item3, Item4에게 비슷한 평점을 매겼다면 그 땐 Item3과 Item4가 비슷한 성격을 지닌 물건이라고 충분히 가정할 만할 것이다.

최근접 이웃 협업 필터링은 대부분 아이템 기반의 알고리즘을 사용한다. 왜? *비슷한 상품을 좋아한다*는 걸 곧바로 유저 취향의 유사성으로 연결짓기엔 비약이 있고, 또 한 가지 이유는 **아이템 수에 비해, 사람 수는 훨씬 더 많기 때문이다.** 평점을 매기는 사람은 적지만, 평점을 받는 아이템은 많다. 즉 사용자의 유사도 파악보다, 아이템의 유사도 파악이 훨씬 쉽다는 거다.

### 코사인 유사도

협업 필터링 알고리즘을 적용하려면 사용자 또는 아이템 간 유사성을 수치적으로 나타낼 수 있어야 한다. 추천 시스템에서는 코사인 유사도를 유사도 측정에 가장 많이 사용한다.

참고로 유사도 측정 방법엔 여러 가지가 있는데, 그 중 가장 많이 쓰이는 것이 유클리드 유사도와 코사인 유사도이다.

![Full-width image](https://github.com/menmenmeng/menmenmeng.github.io/blob/main/assets/img/myown/%EC%9C%A0%EC%82%AC%EB%8F%84.png?raw=true){:.lead loading="lazy"}
왼쪽이 유클리드 유사도, 오른쪽이 코사인 유사도
{:.figure}

- 유클리드 거리 : 점과 점이 얼마나 가까운지를 평가

- 코사인 유사도 : 벡터 관점에서 방향이 얼마나 비슷한지를 평가

사용자-아이템 평점 행렬이 (자연어 처리에서 문장의 단어 출현 빈도를 행렬로 나타낸 그 행렬처럼)다차원 희소 행렬이라는 점에서 코사인 유사도를 쓴다고 하는데.. 일단 둘 간의 가장 큰 차이는 크기 차이가 영향을 주느냐, 아니냐다. User1, User2가 Item1, Item2에 매긴 평점이 각각 (Item1, Item2) 순서쌍으로 (30, 40), (60, 80)이라면 유클리드 유사도 입장에서는 둘은 유사성이 없는 먼 데이터이지만, 코사인 유사도 입장에서는 동일한 데이터인 거다. 

텍스트 분석의 경우 문서의 길이, 추천 시스템의 경우 사용자 간 기준 차이가 유사도 차이를 만들어낼 경우가 존재하기에 이런 맥락에서 방향이 같은지만 보는 코사인 유사도를 사용하는 것일 수도 있겠다.


## 잠재 요인 협업 필터링

사용자-아이템 평점 행렬 데이터만으로 "잠재 요인"을 끄집어 내어, 그걸 바탕으로 추천하는 알고리즘이다. "잠재 요인"이 뭔지는 명확히 정의할 수 없다. 마치 딥러닝의 블랙박스, PCA의 주성분과 비슷한 느낌이다.

다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 <사용자-잠재요인>행렬과 <아이템-잠재요인>행렬로 분해할 수 있다. 그래서 분해한 행렬로 평점이 기록되어 있지 않은 자리의 평점을 예측한다.

행렬을 어떻게 분해하느냐를 간단히 설명하면, shape가 (100, 100)(사용자-아이템)인 행렬을 shape (100, 2), (2, 100)인 행렬 둘의 곱으로 나타낼 수 있다는 것이다. 사용자-아이템 평점 행렬에서 값이 기록되어 있는 요소를 바탕으로 (100, 2) 행렬과 (2, 100) 행렬을 찾으면, 찾은 행렬 두 개를 다시 곱해서 원래의 사용자-아이템 평점 행렬에서 평점이 미부여된 아이템에 대한 예측 평점을 생성할 수 있다. 예측된 평점은 곧 누구에게 무엇을 추천할지에 대한 기준이 될 것이다.

다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법을 행렬 분해(Matrix Factorization)이라고 한다.


## 행렬 분해

SVD(Singular Vector Decomposition), NMF(Non-Negative Matrix Factorization) 등의 방법론이 있다. (M, N)의 shape를 가진 행렬을 (M, K) * (K, N)의 두 행렬의 곱으로 분해하는 방법이다.

위에서 말했듯이 사용자와 아이템의 잠재요인을 행렬 분해 기법을 이용해 표현할 수 있다. 사용자-아이템 평점 행렬 R을 P와 Q.T의 곱으로 나타내는 것이다. 이 때, P는 사용자-잠재요인 행렬, Q는 아이템-잠재요인 행렬이다(.T는 transpose 처리되었다는 뜻).
> R = P * Q.T

원래 SVD는 Null값이 있는 행렬에 대해서 행렬 분해를 해 주는 알고리즘이 아니다. 사용자-아이템 평점 행렬에는 Null값이 상당히 많으니 일반적으로 SVD는 사용할 수 없다. 그래서 사용하는 것이 SGD(확률적 경사 하강법), ALS(Alternating Least Squares)이다.

확률적 경사 하강법, 즉 우리가 아는 기본적인 머신러닝 학습 방법론을 사용한다면 근사된 P, Q를 구할 수 있다.

|         |**Item1**|**Item2**|**Item3**|**Item4**|
|:-------:|:-------:|:-------:|:-------:|:-------:|
|**User1**|        1|        2|         |         |
|**User2**|        1|        1|         |        4|
|**User3**|         |        5|        2|        2|
|**User4**|        2|         |        4|        5|
{:.stretch-table}

위의 사용자-아이템 평점 행렬에서 값이 정의되어 있는 요소들만 고려하여, R과 가장 비슷한 R^를 구한다(R^=P*Q.T이므로 이 얘기는 즉 적절한 P, Q를 구한다는 것과 같다.). 구해진 R^이 R과 충분히 가깝다면, 우리는 R의 요소들 중 정의되지 않은 부분은 R^의 값으로 대체할 수 있다.

 
## 확률적 경사 하강법을 이용한 행렬 분해

- P, Q로 계산된 예측 R행렬 값이 실제 R행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화

- P, Q를 임의의 값을 가진 행렬로 설정한 뒤, R^ 행렬을 계산 --> 오류 값 계산

- 오류값을 최소화하도록 P, Q를 적절한 값으로 업데이트(회귀의 과정과 비슷)

- L2 규제를 고려한다. L1 : 일차, L2 : 이차
    - p_u, q_i의 각 요소들의 L2 norm이 너무 높지 않게, 즉 과적합을 피한다.

- p, q의 변화를 어떻게 계산하는지는 확률적 경사 하강법을 이용한 행렬 분해 - 로 따로 포스팅할 예정. 아직까진 공부 부족..