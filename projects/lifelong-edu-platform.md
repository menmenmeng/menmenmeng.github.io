---
layout: page
title: "평생교육 플랫폼 학습 컨텐츠 분류 및 추천 방안 설계"
description: |
  2022\.11 ~ 2023\.01  
  공공기관 평생교육 플랫폼 현황을 분석하고, 분류 및 추천과 관련된 과제 정의 및 방안을 설계하였습니다.
hide_description: false
sitemap: false
---

0. Table of Contents
{:toc}


회사 내규에 따라 자세한 내용은 생략하였습니다.
{:.faded}


## Background

코로나 19, 저출산 및 고령화 등 여러 가지 환경 변화에 의해 국가기관에서는 평생교육의 중요성이 커지고, 온라인 교육서비스에 대한 수요가 증대할 것이라는 공감대가 형성되었습니다. 이에 따라, 국가평생교육진흥원에서는 현재(2022 기준) 부처/지자체/공공기관에 분산되어 있는 평생교육 인프라를 통합하여 더욱 접근성이 높은 평생교육 통합 플랫폼을 구축하는 제안요청서를 공고하였습니다. LG CNS는 이 제안에 참여하여 프로젝트를 수주하였습니다.

저는 LG CNS에서의 첫 프로젝트로 위의 평생교육 플랫폼 구축 프로젝트에 투입되었으며, 구축 프로세스 중 데이터 분석 과제 도출 및 설계, 수행 파트의 분석 주제 중 아래의 주제에 참여하였습니다.

1. Active Learning 및 텍스트 모델(BERT)을 활용한 학습 콘텐츠 자동 레이블링
2. 학습자의 Feedback 정보를 활용한 ML 기반 추천 모델링

수행 기간 동안 위 주제와 관련하여 As-Is 파악 및 To-Be 설계를 바탕으로 필요한 분석 과제들을 정의하고, 수행 방안을 설계하였습니다. 


## Process

프로젝트의 수행은 2단계를 거치며 진행되었습니다.

- **As-Is 파악 및 요구사항 협의**

  공고된 제안요청서를 바탕으로 고객사의 의도를 파악하고, 데이터 현황 및 현재 활용되는 분석 모델의 운영 현황(As-Is)을 조사하여 고객사의 요구사항이 실제로 이행 가능한지를 가늠하였습니다. 이를 바탕으로, 고객사에서 요청한 요구사항을 구체적으로 정의하고 협의하였습니다.

- **To-Be 설계 및 분석과제 도출, 수행 방안 설계**

  고객사와 협의하여 정리된 요구사항 및 As-Is 분석 결과를 토대로 To-Be를 설계하고, 이에 따라 주제에 맞는 몇 가지의 분석과제를 도출하고 수행 방안을 설계하여 산출물(프레젠테이션 파일)로 작성하였습니다.



### As-Is 파악 및 요구사항 협의

SI 프로젝트 특성상, 고객사의 요구사항, 그리고 데이터 및 시스템 현황에 따라 우리 회사가 이행 가능한 부분을 협의하는 것이 먼저였습니다.

RFP에 나타난 데이터 분석 파트의 요구사항은 크게 <1:학습 콘텐츠 자동 레이블링>, <2:학습 콘텐츠 맞춤형 추천>, <3:학습 경로 설계>의 세 가지의 주제로 나눌 수 있었습니다.

- **학습 콘텐츠 자동 레이블링**
  
  고객사는 여러 플랫폼에 분산된 온라인 강좌(학습 콘텐츠)들을 하나의 플랫폼 내에 통합하면서 강좌의 분류 체계를 정비하고, 강좌의 내용에 따라 자동적으로 강좌의 카테고리가 분류되는 분류기를 만들고 싶어했습니다. 강좌명, 강좌 요약 내용 등의 필드를 토대로 현업자의 공수를 최소화하고 싶어했습니다.
  {:.faded}

- **학습 콘텐츠 맞춤형 추천**
  
  고객사는 통합 플랫폼을 구축하면서 동시에 현재 활용되고 있는 강의 추천 시스템을 고도화하고 싶어했습니다. 현재는 학습자의 취향이나 프로필과 관계 없이, 가장 많은 수강 수를 기록한 강좌 또는 무작위 강좌가 학습자에게 추천되고 있었습니다.
  {:.faded}

- **학습 경로 설계**
  
  고객사는 통합 플랫폼이 평생교육의 관점에서 더 전문성을 가지는 플랫폼이 되길 원했습니다. 이에 따라, 각 학습자의 학습이력 및 프로필 데이터를 바탕으로 평생교육 콘텐츠를 바탕으로 한 학습 경로를 추천해주는 모델을 만들어서 서비스하고 싶어했습니다.
  {:.faded}


저는 첫 번째와 두 번째 주제에 대한 As-Is 분석 및 분석 과제 도출에 깊이 참여하여 프로젝트를 진행하였고, 이 주제와 관련하여 어떤 데이터를 활용할 수 있을지, 그리고 어떤 시스템을 가지고 있는지를 파악하였습니다.


#### 현행 시스템

현재의 평생교육 플랫폼은 국가평생교육진흥원 산하의 늘배움포털, 평생교육계좌제, K-MOOC 등의 플랫폼을 중심으로 여러 부처/지자체/공공기관의 학습 콘텐츠가 연계되어 보여지고 있었습니다. 그러나 연계 방식이 통일되어 있지 않고, 연계되는 콘텐츠 또한 일관적이지 않아 분산된 인프라로 인한 문제점이 존재하는 상황이었습니다.

#### 수집 데이터 파악

1단계 사업에서는 현행 데이터를 직접 받아볼 수가 없었기에 현재 가장 중심이 되는 플랫폼인 늘배움포털 웹사이트를 직접 탐색하며 As-Is를 추정했습니다. 아래는 늘배움포털 내 학습 콘텐츠와 관련하여 수집/관리되는 것으로 추정되는 메타데이터 목록을 정리한 것입니다.

| 운영 기관 | 동영상 제공 방식 | 학습시간 표기 | *진도율 표기* | *강좌명* | *학습분류* | *학습목적* | 강좌이미지 | 강사명 | *강좌 내용* |*평점*| 
|:------:|:---------|:---------------|:------|:------:|:------:|:------:|:------:|:------:|:------:|:-:|
| 강좌 제공 연계 기관 | 1. 늘배움포털 자체 동영상 플레이어를 통해 제공<br>2. 타 사이트의 강좌 링크를 제공<br>3. 링크를 제공하나, 늘배움포털 외의 로그인 아이디가 필요한 경우 등 | 1. 실제 강의 시간으로 표기됨<br>2. 표기 X<br>3. 학습시간이 표기되나 0분으로 표기됨 | 1. 실제 강의 진도율이 표기됨<br>2. 표기 X<br>3. 진도율이 표기되나 항상 0%로 표기됨 | 필수 필드 | 필수 필드 | 필수 필드 | 필수 필드 | 필수 필드 | 하단 세부 내용 정리 |하단 정리|

늘배움포털에 연계되는 학습 콘텐츠의 메타 데이터 목록(추정)
{:.figcaption}

탐색 결과, 늘배움포털에 연계되는 기관마다 들어오는 데이터가 상이했습니다. 기관마다 연계되는 학습 콘텐츠들이 비 통일된 형식으로 제공되었고, 현업자들은 이로 인한 문제가 발생할 경우 대부분 수작업으로 해결하고 있는 상황이었습니다.

위의 메타데이터 중 분석 주제와 관련이 깊은 메타데이터들의 수집/관리 현황을 아래에 자세히 정리하였습니다.

<br>

__평점__

평점은 추천시스템 구축 시 학습자의 명시적인 Feedback정보로서 활용될 수 있기에 살펴보았습니다. 1~5점까지의 점수를 학습 콘텐츠마다 등록할 수 있었으나, 학습 콘텐츠를 듣지 않은 사람도 입력이 가능하였고 평점이 기록된 강좌가 매우 적었습니다.

<br>

__학습이력(진도율)__

학습이력은 추천시스템 구축 시 학습자의 Feedback정보로서 활용될 수 있기에 주의 깊게 살펴보았습니다. 탐색해 보니, 각 교육기관마다 동영상 제공 방식이 달랐고 학습이력 데이터는 이 동영상 제공 방식에 따라 달라졌습니다.  늘배움포털의 자체 동영상 플레이어를 통해 강의가 제공되는 경우 학습이력이 표기되었고 잘 추적되었으나, 그렇지 않고 타 사이트로 강좌 링크를 제공하는 경우에는 학습이력이 표기/추적되지 않는 경우가 많았습니다. 

학습이력 데이터를 활용할 수 있는, 자체 동영상 플레이어를 통해 강의가 제공되는 경우는 어떤 경우인지를 현업자에게 자세히 질의하였으며, 그 결과 이러한 콘텐츠들은 주로 KOCW에서 연계되는 강의이며 현업자가 연계기관에서 동영상 파일을 직접 제공받아 수작업으로 업로드하는 작업을 통해 포털에 게시되고 있었습니다.

학습이력 외에 묵시적인 Feedback으로서, 연계기관과 관계없이 모든 강좌에 대해 학습자가 학습 강좌를 클릭했는지 여부 또한 학습자마다 식별되고 있었습니다.

<br>

__강좌명/강좌 내용__

학습 콘텐츠 자동 레이블링을 위해 강좌명과 강좌 내용을 벡터화하는 텍스트 모델을 활용할 필요가 있었고, 그래서 강좌명과 강좌 내용에 대한 데이터를 주의 깊게 살펴보았습니다. 웹페이지를 탐색한 결과 많은 강좌에 강좌명 및 요약된 강좌 내용이 기재되어 있었으나, 강좌명 필드는 모든 강좌에 기재되어 있었던 반면 강좌 내용은 그렇지 않았습니다. 어떤 강좌들은 강좌 내용 필드에 강좌에 맞는 내용이 적절하게 기재된 반면, 의미가 없거나 강좌명과 동일하거나 아예 기재되지 않은 경우도 많았습니다. 현황파악 결과, KOCW, 인프런, 한국방송통신대학교 등에서 연계되는 강좌가 적절한 강좌 내용이 들어있는 경우가 많으면서도 연계되는 강좌 또한 많았습니다.

<br>

이외에, K-MOOC에서 연계되는 강좌는 늘배움포털 내에서는 진도율이 연계되지 않았고 강좌내용 또한 기재되지 않았지만 같은 국가평생교육진흥원 산하의 기관이었기에, K-MOOC에서 진도율이 기록되고 강좌명과 강좌내용이 기재되어 있다면 이 또한 활용 가능하다고 간주하였습니다.

<br>

__강좌 분류체계(학습분류, 학습목적)__

학습 콘텐츠 자동 레이블링을 위해 현재의 학습 콘텐츠 분류 체계를 정리하였습니다. 학습 콘텐츠는 두 가지의 분류체계를 가지고 분류되고 있었습니다. 하나는 "학습분류"별 분류체계, 하나는 "학습목적"별 분류체계였습니다.

학습분류별 분류체계는 교육기관들의 "평생교육 프로그램 영역별 분류"체계를 그대로 가져온 것으로, 과거에 연구되어 공공기관에서 공식적으로 채택된 평생교육 프로그램 분류체계를 기반으로 만들어진 것입니다. 현업자들이 콘텐츠를 성격에 따라 분류하기에는 좋은 체계지만, 학습자들이 강의를 검색하고 선택하는 것에 있어서는 큰 의미를 가지지 못하는 분류체계입니다.

<p align="center">
  <img width="400" src="https://www.use.go.kr/images/dep/6program.jpg">
</p>

평생교육 프로그램 영역별 분류(울산교육청)
{:.figcaption}

이런 단점을 보완하기 위해, 즉 학습자가 학습목적에 따라 콘텐츠를 원활히 검색하고 선택할 수 있도록 늘배움포털의 현업자들이 자체적으로 만든 분류체계가 학습목적별 분류체계였습니다. '취업/창업', '스포츠', '외국어', '자격증', '음악', '컴퓨터자격증', '인문/교양' 등의 분류를 통해 조금 더 학습자의 입장에 맞춰져 있습니다. 하지만 이 분류체계는 충분한 연구 없이 만들어진 분류 체계로 '취업/창업' 분류 내에 자격증 관련 강의가 있거나 '자격증', '컴퓨터 자격증' 등의 분류가 따로 존재하는 등, 분류의 정의나 분류 간 경계가 모호한 경우가 많았습니다.

또한 학습분류별 분류체계이든, 학습목적별 분류체계이든 현업자가 직접 강좌를 보고 강좌의 분류를 결정해야 하기에 공수가 많이 든다는 단점도 있었습니다. 이러한 여러 단점 때문에 결과적으로 학습 콘텐츠에 대한 분류가 원활히 되지 않았고, 수강 의사가 있는 시민들이 이 점에 대해 불만사항이 많은 상황이었습니다.


### To-Be 및 분석과제 도출/수행 방안 설계

As-Is 파악 후, 수집되는 데이터에 따라 학습 콘텐츠 자동 레이블링, 학습 콘텐츠 맞춤형 추천 두 가지의 분석 주제에 대한 분석 방안을 설계하였습니다.

#### 학습 콘텐츠 자동 레이블링

Active Learning이라는 학습 기법을 기반으로 자동 레이블링 방안을 설계하였습니다. Active Learning은 "좋은 데이터를 활용한다"면, 적은 labeled 데이터로도 충분한 성능을 내는 모델을 만들 수 있다는 가정을 담은 학습 기법입니다. 이번 주제와 같이 레이블 데이터가 많지 않아 모델 학습 이전에 레이블링 작업이 필요한 경우, 레이블링을 위한 수작업을 최소화하는 방안으로 쓰입니다. 

Active Learning을 학습에 적용한다면 모델을 학습시키기 전에 먼저 학습에 좋은 데이터를 찾아내고, 이 데이터를 사람이 우선적으로 레이블링하여 모델에 입력하여 반복적인 모델 학습을 통해 모델의 성능을 점차 높이는 과정을 거칩니다. 따라서, 학습 데이터 샘플링을 위해 '무엇이 좋은 데이터인가?'를 묻는 **쿼리 전략**을 잘 짜는 것이 중요한 요소입니다.

![image](/assets/img/projects/lifelong-edu-active-learning-process.png){:.lead loading="lazy"}

Active Learning의 수행 프로세스
{:.figcaption}

<br>

__데이터 활용__

강좌명 및 강좌 내용이 존재하며, 다수 강좌를 연계하고 있는 **KOCW, K-MOOC, 한국방송통신대학교 등 기관**의 강의를 input 데이터로 활용하도록 하였습니다.

<br>

__분석 방안 설계__

자동 레이블링 모델 설계를 위한 중요한 사안들은 다음과 같았습니다.

- **Active Learning의 쿼리 전략**

  Active Learning에서 주로 활용되는 쿼리 전략을 리서치해 본 결과, Uncertainty 전략과 Core-set 전략의 두 가지 전략이 자주 활용되었습니다.
  
  1. Uncertainty
  
    Uncertainty 전략은 모델이 헷갈리는 데이터를 중요한 데이터로 판단하는 전략으로, 초기 학습된 모델에 unlabeled 데이터를 입력하여 나오는 결과(각 class들의 softmax 확률값)를 봤을 때 균일한 분포의 확률값이 나온다면 이러한 데이터를 중요 데이터로 판단하여 다음에 레이블링할 데이터로 선정합니다.

    <p align="center">
      <img width="400" src="https://blog.kakaocdn.net/dn/E71Zx/btqT3sJroJH/4i2LNf0IfGyRpkZ3keHJE0/img.png">
    </p>

    Uncertainty 전략 : A, B가 중요한 데이터
    {:.figcaption}

  2. Core-set

    Core-set 전략은 데이터 분포를 가장 잘 대표하는 데이터를 중요한 데이터로 판단하는 전략으로, 초기 학습 모델의 추론 결과를 활용하지 않습니다. 얻을 수 있는 unlabeled 데이터의 subset 중, 전체 데이터를 가장 잘 커버하는 subset을 골라 다음에 레이블링할 데이터로 선정합니다. 가장 잘 커버하는 subset을 결정하는 기준은 주로 데이터 간의 거리입니다.

    <p align="center">
      <img width="650" src="https://blog.kakaocdn.net/dn/bnRQpo/btqUzv7wMcC/CeWUEv9oYICk1jv13mGDqk/img.png">
    </p>

    Core-set 전략 : 파란색 점이 중요한 데이터
    {:.figcaption}

  Uncertainty 전략은 구현하기는 쉽지만 각 단계별로 학습된 모델을 활용해 추론하는 과정이 필요하고, 성능면에서 떨어진다는 연구 결과가 많았습니다. 반면 Core-set 전략은 구현은 어렵지만 성능 및 수렴 속도면에서 Uncertainty 전략과 비교해 더 좋다는 연구 결과가 많았습니다. 리서치 후, Core-set 전략을 우선적으로 적용할 쿼리 전략으로 선정하였습니다.


- **Active Learning 활용 시 학습 중지 시점 설정**

  Active Learning의 기본 가정은 "중요한 데이터를 잘 샘플링할 수 있다면, 적은 데이터로도 많은 데이터로 학습한 모델과 비슷한 성능을 낼 수 있다"는 것입니다. 이에 따라, Active Learning을 다룬 많은 연구들은 'Active Learning을 적용한 모델'과, '많은 데이터를 학습시켜 성능의 기준이 되는 모델'을 비교하여 쿼리 전략을 검증하는 경우가 많습니다.

  위와 같은 방식은 실제 사례에서는 적용하기 어렵습니다. unlabeled 데이터밖에 없으므로 '성능의 기준이 되는 모델'을 구축할 방법이 없기 때문입니다. 따라서, 얼마나 많은 Step을 거쳐야 Active Learning을 종료할 수 있는지의 기준을 따로 설정해야 했습니다.

  가능한 방안은 두 가지가 있었습니다. 첫 번째는, 현재까지 학습한 모델의 성능이 기 설정한 절대적 기준을 넘을 경우 학습을 중지하는 방안입니다. 목표치를 타이트하게 잡아 놓고 달성까지 지속적으로 모델을 개선하는 방법이기에 성능면에서 가장 좋겠지만, 제한된 시간 내로 요구사항을 이행해야 하기에 현실적이지 않은 방법이었습니다. 두 번째는, 현재 step의 학습 모델의 성능이 이전 step의 학습 모델의 성능과 비교해 크게 나아진 점이 없는 경우 학습을 중지하는 것으로, 클러스터링 기법에서 최적 군집 수를 찾는 elbow method와 유사합니다. 제한된 시간 내에 절대적 기준을 충족할 수 있다는 보장이 없기에 상대적인 기준을 잡아야 한다고 생각했고, 따라서 이 방법을 활용하기로 하였습니다.


#### 학습 콘텐츠 맞춤형 추천

콘텐츠 유사성을 기반으로 콘텐츠를 추천하는 콘텐츠 기반 필터링과, 학습자의 Feedback 데이터를 활용하여 잠재적 요인을 찾아내는 협업 필터링의 두 가지 방법이 추천 시스템의 대표적인 방법입니다. 이 프로젝트에서는 학습자의 Feedback 데이터 자체가 충분하지 않다는 판단이 있었습니다. 따라서 학습 콘텐츠 추천 시스템 요구사항의 일환으로서 콘텐츠 기반 필터링을 협력사가 설계하고, 이와 더불어 저희 팀에서 추가 제언으로 잠재 요인 협업 필터링을 제시하였습니다.

자세한 데이터 파악이 불가한 상황이었기에, 향후 과제 이행 시 데이터를 자세히 파악하고 그에 따라 유동적인 이행이 가능하도록 계획하였습니다.

__데이터 활용__

Explicit & Implicit Feedback 데이터(평점, 학습이력, 학습콘텐츠 클릭 여부 등)가 수집되는 학습 콘텐츠 및 학습자를 대상으로 잠재 요인 협업 필터링 모델을 활용하도록 하였습니다. 

__분석 방안 설계__

학습 콘텐츠 추천 모델을 위한 중요한 사안들은 다음과 같았습니다.

- **Rating Matrix의 정의**

  Explicit & Implicit Feedback 데이터가 존재하긴 했으나 명시적으로 "평점"의 형태로 활용할 수 있는 데이터는 많지 않았기에 협업 필터링 모델에 활용할 수 있도록 적절하게 변형하는 과정이 필요했습니다. 아래와 같은 세 가지 방법을 고려하였습니다.

  1. 명시적 평점 데이터 활용
    
    학습 콘텐츠에 대한 평점 데이터가 적게나마 존재하였기에, 이를 활용하여 협업 필터링 모델을 구축합니다. 기본적인 방법이지만, 현 상황에서 활용할 수 있는 데이터가 적고 현재 기록되고 있는 평점 데이터에 대한 신뢰성이 부족하다는 문제가 있습니다.

  2. BPR(Bayesian Personalized Ranking)

    학습 콘텐츠를 클릭하였는지 여부를 Implicit Feedback으로 간주하여, 이를 바탕으로 학습자가 가진 학습 콘텐츠의 흥미도의 비교 우위를 맞추도록 협업 필터링 모델을 구축하는 방법입니다. 절대적 수치가 아닌 상대적인 비교 우위를 맞추는 방법이기에 Explicit Feedback이 부족한 이번 과제와 같은 곳에 유용하게 쓰일 수 있습니다.

  3. Feedback을 조합한 Score 산출

    Explicit Feedback과 Implicit Feedback을 적절히 조합하여 pseudo-평점을 만드는 방식입니다. 산출식에 따라 모델 편차가 크겠지만 확장성이 높다는 강점이 있고, Sparsity Problem을 고려해야 하는 비중이 적습니다.

  세 번째 방법인 Score 산출 방식을 우선적으로 적용하여 모델을 구축하기로 하였으며, 향후 과제 이행 시 데이터 현황을 자세히 파악하여 나머지 두 가지 방법을 유동적으로 활용하기로 하였습니다.


- **추천 알고리즘**

  1. Matrix Factorization

    가장 기본적인 잠재 요인 협업 필터링 모델로, 학습자의 Feedback 데이터만을 활용하는 방식입니다. 평점이 없는 학습자/학습 콘텐츠의 경우 이 모델을 활용하기 어렵다는 단점이 있습니다(Cold-Start 문제).

    ![image](/assets/img/projects/lifelong-edu-MF.png){:.lead loading="lazy"}

    Matrix Factorization
    {:.figcaption}


  2. Factorization Machine

    Matrix Factorization에 일반적 회귀 모델(SVM 등)을 결합한 것으로, 학습자의 Feedback 데이터와 함께 학습자 자체 속성 및 학습 콘텐츠 자체 속성을 또 다른 column으로 활용하는 방법입니다. Cold-Start 문제에 강건하다는 장점이 있으나, Feedback 데이터 외 일반 속성으로 무엇을 활용할지에 대해서는 고민이 필요합니다.

    ![image](/assets/img/projects/lifelong-edu-FM.png){:.lead loading="lazy"}

    Factorization Machine
    {:.figcaption}

  리서치를 통해 위와 같은 두 가지 방법론을 활용하기로 하였으며, 이행 시 콘텐츠 기반 필터링 방법론과 함께 사용하여 성능이 높은 모델을 찾도록 하였습니다.

- **추천 모델의 성능 평가 기준**

  추천 모델에 대한 성능 평가는 두 가지 방법을 활용할 수 있습니다. 첫 번째 방법은 평점 예측 오차를 평가하는 것으로, 예측 평점의 정확도를 맞추는 방법입니다. 수식적 관점에서 다루기 편리하지만 평점이 학습자의 의도를 정확히 반영하고 있다는 가정이 필요합니다. 두 번째 방법은 추천 아이템 예측 오차를 평가하는 것으로, 추천되는 콘텐츠와 실제 학습자가 학습한 콘텐츠가 유사한지를 평가합니다. 모델의 궁극적인 의도를 반영하는 방법입니다.

  ![image](/assets/img/projects/lifelong-edu-metrics.png){:.lead loading="lazy"}

  추천 모델의 성능 평가 방법
  {:.figcaption}

  평점 예측 오차 평가 방식의 경우 모델 학습을 위한 Gradient 계산에 활용하고, 추천 아이템 예측 오차 평가 방식의 경우 최종적인 모델의 아이템 추천 성능을 평가하여 모델을 선택하는 기준으로 활용하도록 하였습니다.

<br>

위와 같이 두 가지 주제에 대한 수행 방안을 설계하고, 이를 PowerPoint를 활용한 산출물로 작성하였습니다.

## Meaning

단점 1. 이행하지 못하고 빠졌음 단점 2. 데이터를 제대로 보지 못해 계획만 세우고 실제 이행이 가능한지 여부를 판단하기가 너무 어려웠음

장점 1. 회사간의 협업, 팀간의 협업에서 프레젠테이션과 산출물의 중요성 .... 또?



## Skills

Powerpoint


Go back to [Myeong Hyeon Son](/about/#projects){:.heading.flip-title}
{:.read-more}