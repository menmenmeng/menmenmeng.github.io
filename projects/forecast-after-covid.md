---
layout: page
title: "코로나 팬데믹 이후 품목별 소비 예측"
description: |
  2021\.09 ~ 2021\.11  
  빅데이터 캠퍼스 및 서울열린데이터광장에서 제공하는 서울시민의 카드 소비 데이터를 활용하여 코로나 이후 품목별 소비를 분석한 팀 프로젝트입니다.
hide_description: false
sitemap: false
---

0. Table of Contents
{:toc}


## Background

2021년 데이터 분석 학회에 가입하여 머신러닝 전반에 필요한 데이터 분석 코딩 스킬들을 익히고, 이를 활용해 보기 위해 진행했던 프로젝트입니다. 공공 데이터를 기반으로 사회 문제를 해결하고 비즈니스 모델을 구성하는 빅데이터 캠퍼스의 공모전이었으며, 4명의 팀으로 참여하여 프로젝트를 수행하였습니다. 

2021년 중순 이후 코로나 감염자가 급증하며 주요 이슈로 떠올랐습니다. 성인의 절반 가량이 코로나로 인한 직접적인 경제적 피해를 받고 있다는 통계, 그리고 전 세계인의 48%가 코로나로 인해 소비 습관이 바뀌었다는 통계 등을 통해 코로나 팬데믹 기간 동안 시민들의 소비 습관에 큰 변화가 있음을 알 수 있었습니다. 이에 반응하여 정부는 소비 활성화를 위한 소비 쿠폰을 보급한다는 정책을 내놓거나 코로나 19 대응을 위한 예산을 604조가량 책정하는 등 지원 정책을 발표했습니다. 저희는 그에 맞추어 한정된 예산을 더 효율적으로 운용할 수 있도록 코로나 팬데믹 이후의 소비를 예측하고 지원이 시급한 업종을 찾을 수 있는 방법을 제시하고자 하였습니다.


## Process

### Data Processing

빅데이터 캠퍼스의 분석실 내에서 사용 가능한 비공개 데이터인 1. 서울시민의 업종별 카드소비 패턴 데이터, 2. 행정동 단위 거주인구 데이터, 3. 서울시 상권발달 개별지수 등 3가지 데이터를 활용하여 주된 시각화 및 분석을 진행하였고, 분석실 외에서도 분석 작업을 할 수 있는 데이터인 4. 통계청 온라인 쇼핑 동향 조사 데이터를 사용해 추가적인 시계열 분석을 진행하였습니다. 전체적인 프로세스는 다음과 같습니다.

<p align="center">
  <img width="500" src="/assets/img/projects/covid-process-all.jpg">
</p>

4명의 팀원을 시각화와 모델링, 두 파트로 나누어 분업하여 프로젝트를 수행하였습니다. 시각화 팀은 PowerBI를 활용하여 구별로 코로나 전후의 소비 변화를 업종에 따라 비교하는 차트를 만들었고, 저는 모델링 팀에 포함되어 팀원과 함께 코로나 이후의 소비를 예측할 만한 모델을 구축하려 했습니다.

분석 모델을 만들기 전, 3개의 데이터 테이블을 join하여 하나의 데이터로 만드는 과정을 거쳐야 했습니다. 이 과정에서 자치구 및 업종을 기준으로 데이터를 묶어내려 하였는데, 데이터의 발행 주체가 달라 행정동 코드를 나누는 기준이 달라 문제가 생겼습니다. 두 데이터 발행 주체의 행정동 구분 코드를 매핑하여 코드 맵을 만들고, 이 코드 맵을 따라 데이터 테이블을 묶는 과정을 거쳐 최종적으로 분석에 사용할 하나의 테이블을 만들었습니다.

이후, 분석 모델을 구축해야 했는데 저희는 많은 머신러닝 프로젝트에서 사용되는 RandomForest 기반의 분석 모델을 시계열 분석 모델로 활용하고 싶었습니다. 이에 따라, 아래와 같이 과거 6개월의 데이터를 이어 붙여 하나의 row로 만드는 과정을 통해 새로운 데이터 테이블을 만들어 분석 데이터로 활용하였습니다.

![covid-time-series-data](/assets/img/projects/covid-time-series-data.jpg){:.lead loading="lazy"}


### Modeling

구별/업종별/월별로 나누어진 몇 천 개의 row를 가진 위 데이터를 Train/Test 세트로 분할하여 모델을 학습하였습니다. 2018년 7월 ~ 2020년 4월까지의 데이터를 Train 세트로, 2020년 5월 ~ 2020년 9월까지의 데이터를 Test 세트로 분할하여 RandomForest 모델을 학습했습니다. 모델 학습 후 Test 세트로 예측 결과를 확인해보니, 교육, 마트, 여행, 음식 업종에서는 좋은 성능을 보여주었지만 자동차, 유흥, 통신 등의 업종에서는 좋지 않은 성능을 기록했습니다.

이외에, 빅데이터 캠퍼스 내규 상 빅데이터 캠퍼스와 데이터베이스가 연결되어 있는 분석실에서만 분석이 가능했고, 분석실의 오픈 시간이 정해져 있었기에 분석실이 열려 있지 않은 동안 다른 데이터를 이용하여 분석 모델을 구축하기도 하였습니다. 구별로 코로나 전후의 소비 변화를 시각화한 차트에서, 많은 구에서 온라인 쇼핑몰의 업종이 상위를 차지하고 있었습니다. 이에 따라, 통계청에서 제공하는 온라인 쇼핑 동향 조사 데이터를 활용하여 Prophet이라는 시계열 분석 라이브러리를 활용한 분석 또한 진행하였습니다.

위의 분석 모델들을 구축하여, 정보가 최신화되었을 경우 업종에 따른 소비의 변화를 시계열 데이터를 통하여 분석하고 코로나 이후의 정부 정책에 반영할 가능성을 프레젠테이션하였습니다.


## Meaning

분석 방법론에 대해서는 공부하였으나 파이썬 데이터 분석 코딩에는 익숙하지 않았기에 학회에 가입한 후로 파이썬 데이터 분석 스킬을 익히고, 이 프로젝트를 통해 공부한 스킬들을 활용하는 기회를 가졌습니다. 특히 데이터베이스를 파이썬으로 쿼리하여 추출하고, 이를 파이썬 사이킷런의 모델을 이용해 학습하는 일련의 과정을 거치면서 파이썬 활용에 대해서는 많이 배웠다고 생각합니다.

2022년 기준, 이 프로젝트의 내용을 보면 만족하지 못한 부분이 많습니다. 이론적으로 부족한 부분 때문이기도 했지만 빅데이터 캠퍼스 공모전 특성상 오프라인에 마련된 분석실에 직접 가야만 분석을 할 수 있었기에 시간적으로 제한이 있었기 때문이기도 합니다. 아쉬운 부분입니다.

데이터 분석 자체보다는 팀 프로젝트의 효율적이고 완벽한 진행은 어떻게 해야 하는지에 대한 고민을 많이 가져왔던 프로젝트였습니다. 시각화와 모델링의 두 파트로 나누었던 결정이 나중에 좋지 않은 결과로 돌아왔는데 그 이유는 서로 같은 데이터에 대해 전처리를 다르게 했기 때문이었습니다. 시각화 파트는 데이터의 row수가 많아 처음 추출할 때 무작위 추출을 하여 시각화를 진행하였고, 모델링 파트는 전체 데이터를 추출하여 모델을 학습하였습니다. 최종 마감이 얼마 남지 않은 시점에 이를 알아채고 시각화 파트와 모델링 파트가 데이터를 통일하여 다시 모델을 구축하였습니다. 전처리 파트는 데이터 분석에서 가장 중요한 파트이자 기본이 되는 파트이기 때문에 모든 인원이 함께 했어야 했습니다. 모델링 파트를 함께한 조원과는 함께 많은 얘기를 나누며 적절하게 작업을 분배했습니다.

공공데이터를 활용하는 프로젝트의 주제에는 대부분 "최적 위치 선정"이라는 말이 들어갑니다. 이 주제를 피하기 위해 많은 노력을 했지만, 결과적으로 프로젝트를 진행할수록 "최적 위치 선정"이라는 주제가 흔했던 이유를 알 것 같았습니다. 좋은 인사이트를 만들어내기 위해 여러 데이터 테이블을 활용해야 하는데, 공공데이터에서는 이러한 데이터 테이블들을 묶어 줄 만한 공통된 key가 지역적, 위치적 데이터인 경우가 대부분이었기 때문입니다. 결과적으로 지역적 데이터를 활용하여 분석을 진행하게 되었습니다.

코로나 이후의 소비 데이터를 예측하는 프로젝트인데, 결과적으로 팬데믹과 관련된 직접적인 데이터는 활용하지 못했다는 점이 가장 큰 아쉬움입니다. 과거 메르스 사태, 신종플루 등 시간대에서의 SNS 데이터를 스크래핑할 계획을 세웠었지만 데이터 추출 기준이나 과거 몇 년 전의 데이터를 추출하기 위한 코드를 짜는 과정은 마감 전까지 끝내기엔 번거로운 작업이었기에 결국 공공데이터만으로 프로젝트를 마무리하게 되었습니다.



## Skills

Python(numpy, pandas, scikit-learn)


Go back to [Myeong Hyeon Son](/about/){:.heading.flip-title}
{:.read-more}